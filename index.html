<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
</head>
<meta name="description" content="Wenxiang Jiao&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Wenxiang Jiao (焦文祥)'s Homepage</title>


	
<body>
<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                    <h1>Wenxiang Jiao (焦文祥) &nbsp; </h1>
                </div>
                <h3>Senior Researcher</h3>
                <p>
                    NLP Center <br>
                    Tencent AI Lab <br>
                    Shenzhen, China <br>
                    <br>
                    E-mail: wenxiangjiaonju@gmail.com <br>
                    <a href="https://scholar.google.com/citations?user=CvtODukAAAAJ&hl=en">Google Scholar</a> <br>
                    <a href="https://github.com/wxjiao">GitHub</a> <br>
		<!--
		    <a href="To-be-decided">Research Statement</a>
		-->
                </p>
		<p>
    		    <font color="red"><b>Collaboration is WELCOME!</b></font>
		</p>

            </td>
            <td>
                <img src="./profile.jpg" border="0" width="150">
            </td>
        </tr>
    </tbody>
</table>
	

<h3>&#x1F525 News &#x1F525</h3>
<p>
	<!--
	<ul>&#x1F336 AVAILABLE: Looking for research interns! Please drop me your CV if you're interested in neural machine translation (NMT) and pre-training.
	</ul>
	-->
	<ul> <b>2022-10-06</b>: One paper accepted to EMNLP 2022 (Findings). 
	</ul>
	<ul> <b>2022-09-24</b>: Won <a href="https://docs.google.com/spreadsheets/d/1NHwPkIK7b5pjTcnZdlH1cxS_orbISjdOv5V12aHj1iY/edit#gid=1337958767"><b>1st place (team: Borderline)</b></a> at WMT'2022 Large-Scale Machine Translation Evaluation for African Languages (Constrained Track). 
	</ul>
	<ul> <b>2022-04-26</b>: Self-developed Chinese<=>Japanese translation systems launched on <a href="https://transmart.qq.com/zh-CN/index"><b>Tencent TranSmart</b></a>. 
	</ul>
	<ul> <b>2022-02-24</b>: One paper accepted to ACL 2022. 
	</ul>
	<ul> <b>2022-02-01</b>: One paper accepted to IEEE Transactions on Audio, Speech and Language Processing. 
	</ul>
	<ul> <b>2021-11-02</b>: Joined Tencent AI Lab as a Senior Researcher. 
	</ul>
	<ul> <b>2021-09-15</b>: Our project on "Exploiting Large-Scale Data for NMT" won the <a href="https://cloud.tencent.com/developer/article/1879377?from=article.detail.1746685"><b>Technology Innovation Award</b></a> (top 10%) of 2020 Tencent AI Lab Rhino Bird Project!
	</ul>
	<ul> <b>2021-08-26</b>: Just passed my Ph.D. oral defense. Many thanks to my supervisors and committees!
	</ul>
</p>

	
<h2>Biography</h2>
<p>
    I'm now working at Tencent AI Lab, focusing on researches regarding multilingual NMT and pretraining for NMT. </a>
    Before that, I just received my Ph.D degree from The Chinese University of Hong Kong, under the supervision by Prof. Irwin King and Prof. Michael R. Lyu. </a> 
    My Bachelor degree and Mphil degree were both achieved at Nanjing University in 2015 and 2017, respectively. <br>
    The time line of my research is presented as below:
    <ul>
	<li>
            <b>2021-Now</b>: Improving multilingual pretraining models (ACL'22, EMNLP'22) and multilingual NMT (WMT'22).
        </li>
        <li>
            <b>2019-2021</b>: Exploiting parallel data (EMNLP'20; TASLP'22) and monolingual data (ACL'21) for NMT by data augmentation.
        </li>
	<li>
            <b>2017-2019</b>: Hierachical modeling (NAACL'19; AAAI'20) and pretraining (EMNLP'20 Findings) for emotion recognition in conversations.
        </li>
    </ul>
</p>


<h2>Interns <small></small></h2>
<table id="tbTeaching" border="0" width="100%">
    <tbody>
	I have benefited a lot from working with these excellent interns.
        <ul>
	    <li>
                <div style="float:right;">Mar. 2022 - Now</A></div>
                <a href="TBD">Jen-tse Huang</a>: Chinese University of Hong Kong <br>
                Directions: Robustness in multilingual pretrained models <br>
            </li>
	    <li>
                <div style="float:right;">Aug. 2021 - Now</A></div>
                <a href="https://yifan-h.github.io/">Yifan Hou</a>: ETH Zurich <br>
                Directions: Multilingual pretrained LMs, multilingual KG <br>
            </li>
            <li>
                <div style="float:right;">Aug. 2021 - Now</A></div>
                <a href="https://scholar.google.com/citations?user=4v5x0bUAAAAJ&hl=en">Wenxuan Wang</a>: Chinese University of Hong Kong <br>
                Directions: Pretraining for NMT, multilingual NMT <br>
            </li>
            <li>
                <div style="float:right;">Aug. 2021 - Aug. 2022</A></div>
                <a href="TBD">Jiarui Li</a>: Chinese University of Hong Kong (Shenzhen) <br>
                Directions: Adapting multilingual MT and MAE into THUMT <br>
            </li>
        </ul>
    </tbody>
</table>


<h2>Publications <small></small></h2>
<ul>
    <a href="https://arxiv.org/abs/2210.09644">Tencent’s Multilingual Machine Translation System for WMT22 Large-Scale African Languages</a> <br>
    <b>Wenxiang Jiao</b>, Zhaopeng Tu, Jiarui Li, Wenxuan Wang, Jen-tse Huang and Shuming Shi <br>
    <div style="float:right;"><a href="https://github.com/wxjiao/WMT2022-Large-Scale-African">[code]</a></A></div>
    <i>WMT 2022</i>
</ul>
<ul>
    <a href="TBD">A Knowledge-Enhanced Multilingual Language Model for Both Knowledge Graph and Language Tasks</a> <br>
    Yifan Hou, <b>Wenxiang Jiao</b>, Meizhen Liu, Carl Allen, Zhaopeng Tu and Mrinmaya Sachan <br>
    <i>EMNLP 2022 (Findings)</i>
</ul>
<ul>
    <a href="https://aclanthology.org/2022.acl-long.185/">Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation</a> <br>
    Wenxuan Wang, <b>Wenxiang Jiao</b>, Yongchang Hao, Xing Wang, Shuming Shi, Zhaopeng Tu, Michael R. Lyu <br>
    <i>ACL 2022</i>
</ul>
<ul>
    <a href="https://ieeexplore.ieee.org/document/9721161">Exploiting Inactive Examples for Natural Language Generation with Data Rejuvenation</a> <br>
    <b>Wenxiang Jiao</b>, Xing Wang, Shilin He, Zhaopeng Tu, Irwin King, Michael R. Lyu <br>
    <i>IEEE/ACM Transactions on Audio, Speech, and Language Processing. 2022. </i>
</ul>
<ul>
    <a href="https://aclanthology.org/2021.acl-long.221.pdf">Self-training Sampling with Monolingual Data Uncertainty for Neural Machine Translation</a> <br>
    <b>Wenxiang Jiao</b>, Xing Wang, Zhaopeng Tu, Shuming Shi, Michael R. Lyu, Irwin King <br>
    <div style="float:right;"><a href="https://github.com/wxjiao/UncSamp">[code]</a></A></div>
    <i>ACL 2021</i>
</ul>
<ul>
    <a href="https://www.aclweb.org/anthology/2020.emnlp-main.176/">Data Rejuvenation: Exploiting Inactive Training Examples for Neural Machine Translation</a> <br>
    <b>Wenxiang Jiao</b>, Xing Wang, Shilin He, Irwin King, Michael R. Lyu, Zhaopeng Tu <br>
    <div style="float:right;"><a href="https://github.com/wxjiao/Data-Rejuvenation">[code]</a></A></div>
    <i>EMNLP 2020</i>
</ul>
<ul>
    <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.435/">Exploiting Unsupervised Data for Emotion Recognition in Conversations</a> <br>
    <b>Wenxiang Jiao</b>, Michael R. Lyu, Irwin King <br>
    <div style="float:right;"><a href="https://github.com/wxjiao/Pre-CODE">[code]</a></A></div>
    <i>EMNLP 2020 (Findings)</i>
</ul>
<ul>
    <a href="https://aaai.org/ojs/index.php/AAAI/article/view/6309">Real-Time Emotion Recognition via Attention Gated Hierarchical Memory Network</a> <br>
    <b>Wenxiang Jiao</b>, Michael R. Lyu, Irwin King <br>
    <div style="float:right;"><a href="https://github.com/wxjiao/AGHMN">[code]</a></A></div>
    <i>AAAI 2020</i>
</ul>
<ul>
    <a href="https://www.aclweb.org/anthology/N19-1037/">HiGRU: Hierarchical Gated Recurrent Units for Utterance-Level Emotion Recognition</a> <br>
    <b>Wenxiang Jiao</b>, Haiqin Yang, Irwin King, Michael R. Lyu <br>
    <div style="float:right;"><a href="https://github.com/wxjiao/HiGRUs">[code]</a></A></div>
    <i>NAACL-HLT 2019</i>
</ul>
<ul>
    <a href="https://arxiv.org/abs/2010.12868">Multi-Task Learning with Shared Encoder for Non-Autoregressive Machine Translation</a> <br>
    Yongchang Hao, Shilin He, <b>Wenxiang Jiao</b>, Zhaopeng Tu, Michael Lyu, Xing Wang <br>
    <i>NAACL-HLT 2021</i>
</ul>
<ul>
    <a href="https://arxiv.org/abs/1910.09362">Improving Word Representations: A Sub-sampled Unigram Distribution for Negative Sampling</a> <br>
    <b>Wenxiang Jiao</b>, Irwin King, Michael R. Lyu <br>
    <i>Technical Report 2019</i>
</ul>


<h2>Academic Activity</h2>
<p>
    <ul>
        <div style="float:right;"><i>2022</i></A></div>
        Workshop speech at NLPCC 2022 <br>
        Reviewer of ACL/ARR 2022
    </ul>
    <ul>
        <div style="float:right;"><i>2021</i></A></div>
        Reviewer of the Neurocomputing Journal <br>
        Reviewer of ACL 2021
    </ul>
    <ul>
        <div style="float:right;"><i>2020</i></A></div>
        Research talk at AI TIME on <a href="https://mp.weixin.qq.com/s/8MuanSkAmhKf5IwM5JUGbA">Data Rejuvenation</a> <br>
        Reviewer of ACL 2020, AAAI 2021 <br>
        Secondary reviewer of EMNLP 2020, COLING 2020, EACL 2020
    </ul>
</p>


<h2>Experiences <small></small></h2>
<table id="tbTeaching" border="0" width="100%">
    <tbody>
        <ul>
            <li>
                <div style="float:right;">Oct. 2019 - Dec. 2019</A></div>
                Research Intern: <a href="https://ai.tencent.com/ailab/zh/index/">Tencent AI Lab</a> <br>
                Mentor: <a href="http://www.xingwang4nlp.com/">Xing Wang</a>, <a href="http://www.zptu.net">Zhaopeng Tu</a> <br>
                Worked on data analysis and exploitation in neural machine translation. <br>
                Published one paper to EMNLP 2020, ACL 2021 and TASLP 2022, respectively.
            </li>
        </ul>
    </tbody>
</table>


<h2>Paper Reading</h2>
<p>
    <ul>
        <div style="float:right;"><i>Jun. 2021</i></A></div>
	Multi-Task Learning for Multilingual Neural Machine Translation (ACL 2020-2021) <a href='./reading/paper-reading-20210607.pdf'>[slides]</a>
    </ul>
    <ul>
        <div style="float:right;"><i>Nov. 2020</i></A></div>
	Exploiting Monolingual Data at Scale for Neural Machine Translation (EMNLP 2019) <a href='./reading/paper-reading-20201109.pdf'>[slides]</a>
    </ul>
    <ul>
        <div style="float:right;"><i>Aug. 2020</i></A></div>
	A Closer Look at Memorization in Deep Networks (ICML 2017) <a href='./reading/paper-reading-20200806.pdf'>[slides]</a>
    </ul>
    <ul>
        <div style="float:right;"><i>Jul. 2020</i></A></div>
	Towards Explaining the Regularization Effect of Initial Large Learning Rate in Training Neural Networks (NeurIPS 2019) <a href='./reading/paper-reading-20200709.pdf'>[slides]</a>
    </ul>
</p>


<!--
<h2>Teaching Assistant</h2>
<p>
    <ul>
        <div style="float:right;"><i>2020 Fall</i></A></div>
        ENGG 1110: Problem Solving By Programming
    </ul>
    <ul>
        <div style="float:right;"><i>2020/2019/2018 Spring</i></A></div>
        CSCI 3100: Software Engineering
    </ul>
    <ul>
        <div style="float:right;"><i>2018 Fall</i></A></div>
        CSCI 2720: Building Web Applications
    </ul>
</p>
-->

<h2>Education</h2>
<p>
    <ul>
        <div style="float:right;"><i>Shatin, NT, Hong Kong</i></A></div>
        The Chinese University of Hong Kong (CUHK) <br>
        <div style="float:right;"><i>Aug. 2017 - Aug. 2021</i></A></div>
        Doctor of Philosophy Student, Computer Science & Engineering <br>
        Advisor: <a href="https://www.cse.cuhk.edu.hk/irwin.king/">Irwin King</a> (IEEE Fellow), and <a href="http://www.cse.cuhk.edu.hk/lyu/">Michael R. Lyu</a> (IEEE Fellow, ACM Fellow)
    </ul>
    <ul>
        <div style="float:right;"><i>Nanjing, China</i></A></div>
        Nanjing University (NJU) <br>
        <div style="float:right;"><i>Sep. 2015 - Jun. 2017</i></A></div>
        Mphil of Engineering, Optical Engineering <br>
        Advisor: <a href="https://scholar.google.com/citations?user=knxohNwAAAAJ&hl=en">Guanghui Wang</a>
    </ul>
    <ul>
        <div style="float:right;"><i>Nanjing, China</i></A></div>
        Nanjing University (NJU) <br>
        <div style="float:right;"><i>Sep. 2011 - Jun. 2015</i></A></div>
        Bachelor of Engineering, Information Engineering <br>
    </ul>
</p>


<h2>Awards</h2>
<p>
    <ul>
	<div style="float:right;"><i>Tencent, 2022</i></A></div>
	<b>1st place </b></a> at WMT'2022 Large-Scale Machine Translation Evaluation for African Languages (Constrained Track) <br>
    </ul>
    <ul>
	<div style="float:right;"><i>CUHK, 2021</i></A></div>
	Technology Innovation Award (top 10%) of 2020 Tencent AI Lab Rhino Bird Project <br>
    </ul>
    <ul>
        <div style="float:right;"><i>CUHK, 2017 - 2021</i></A></div>
        Full Postgraduate Studentship <br>
    </ul>
    <ul>
        <div style="float:right;"><i>NJU, 2016</i></A></div>
        Huawei Scholarship <br>
    </ul>
    <ul>
        <div style="float:right;"><i>NJU, 2015</i></A></div>
        Outstanding Graduates Award <br>
    </ul>
    <ul>
        <div style="float:right;"><i>NJU, 2014</i></A></div>
        Bejing Bank Outstanding Scholarship <br>
    </ul>
    <ul>
        <div style="float:right;"><i>Ministry of Education of China, 2013</i></A></div>
        China National Scholarship <br>
    </ul>
    <ul>
        <div style="float:right;"><i>COMAP, 2014</i></A></div>
        Honorable Mentions in American Mathematical Contest in Modeling (MCM) <br>
    </ul>
    <ul>
        <div style="float:right;"><i>CSIAM, 2014</i></A></div>
        Honorable Mentions in National College Mathematical Contest in Modeling <br>
    </ul>
    <ul>
        <div style="float:right;"><i>COS, 2014</i></A></div>
        Honorable Mentions in National College Optoelectronic Design Competition <br>
    </ul>
</p>


<h2>Skills</h2>
<p>
    <ul>
        Programming Languages: Python, C/C++, Matlab
    </ul>
    <ul>
        Deep Learning Frameworks: Pytorch, Tensorflow
    </ul>
</p>


<h2>Language</h2>
<p>
    <ul>
        TOEFL: 100
    </ul>
    <ul>
        GRE: V154 + Q170 + AW3.5
    </ul>
</p>


<div id="footer">
    <div id="footer-text"></div>
</div>

</div>

Last updated on Oct 2022.
</body></html>
